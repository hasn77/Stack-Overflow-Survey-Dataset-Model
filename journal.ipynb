{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db55cacd",
   "metadata": {},
   "source": [
    "## ____Stack Overflow Survey ML Project - Learning Journal____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8c6ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAW DATA\n",
    "  # └──> EDA (distributions, correlations, plots, intuition)\n",
    "    #     └──> Preprocessing (handle missing, encode categoricals, bin experience, log salary)\n",
    "      #        └──> Transformers & Pipeline (reusable, scalable, leak-proof)\n",
    "       #             └──> Scaling (StandardScaler)\n",
    "        #                  └──> Modeling (linear regression on log(salary))\n",
    "         #                       └──> Evaluation & Interpretation\n",
    "          #                            └──> Journal documentation & insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238df457",
   "metadata": {},
   "source": [
    "#### ___Project Overview___\n",
    "- Dataset: Stack Overflow 2023 Survey\n",
    "- Goal: __Predicting Yearly Salary (ConvertedComppYearly)__\n",
    "- Key Learning Objectives: Apply Chapter 2 concepts, feature engineering practice, robust pipeline building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ff3543",
   "metadata": {},
   "source": [
    "#### ___Target Selection___\n",
    "- **Decision**: ConvertedCompYearly as regression target\n",
    "- **Why**: \n",
    "  - 48K samples, reasonable distribution\n",
    "  - Median $75K aligns with industry knowledge\n",
    "  - Rich feature set for prediction\n",
    "- **Challenges identified**: \n",
    "  - Extreme outliers need handling\n",
    "  - ~46% missing values\n",
    "  - Need currency/location normalization strategy\n",
    "- **Next**: Explore feature relationships and outlier handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f07b6a3",
   "metadata": {},
   "source": [
    "####  ___Documentation___\n",
    "\n",
    "#### __Data Exploration__\n",
    "- **Decision**: Checked the dataset for missing values, saw statistical descriptions of each variable.  \n",
    "- **Why**: To find out a reasonable target variable. \n",
    "- **Alternatives considered**: N/A\n",
    "- **Outcome**: Most of the variables are objects/categorical. The model would require clever data preprocessing to find out only relevant variable for the target. Then onwards clever feature engineering would help to build a strong model.\n",
    "\n",
    "#### __Feature Selection__\n",
    "- **Features**: EdLevel, YearsCode, YearsCodePro, DevType, OrgSize, TechList, LanguageHaveWorkedWith, PlatformHaveWorkedWith, WebframeHaveWorkedWith, ToolsTechHaveWorkedWith, WorkExp, Industry, ProfessionalTech.\n",
    "- **Statistics**: 12 out of 13 features are object/categorical mostly highly cordinal. \n",
    "- **Choice**: Based on the tech domain intuition, these features are most likely to relate the most and can be the drivers of tech salaries. \n",
    "- **Challenges**: None so far."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4481cd84",
   "metadata": {},
   "source": [
    "#### ✨ **Feature Engineering Strategy**\n",
    "\n",
    "<details>\n",
    "  <summary><strong>📂 Click to expand details</strong></summary>\n",
    "\n",
    "---\n",
    "\n",
    "## 🎯 Topic: Advanced Feature Engineering for High-Cardinality Categorical Variables\n",
    "\n",
    "---\n",
    "\n",
    "### 📝 **Problem Context**\n",
    "Working with the Stack Overflow survey data:\n",
    "- **13 variables** (12 categorical, 1 numerical)\n",
    "- **~89,000 rows**\n",
    "\n",
    "The main challenge:  \n",
    "👉 High-cardinality categorical variables like `TechList` and `LanguageHaveWorkedWith` could explode into **thousands of sparse features** if naïvely one-hot encoded.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 **Key Insights Discovered**\n",
    "\n",
    "**1️⃣ The Sparse Matrix Strategy**\n",
    "- **Problem:**  \n",
    "  One-hot encoding all 12 categoricals creates potentially **10K+ features** with **99%+ zeros**.\n",
    "- **Solution:**  \n",
    "  Use sklearn’s sparse matrix support with `feature_names_out` for interpretability.\n",
    "- **Why it works:**  \n",
    "  Sparse matrices store only non-zero values, reducing memory usage by **90-95%**.\n",
    "\n",
    "---\n",
    "\n",
    "**2️⃣ Hierarchical Feature Engineering Approach**\n",
    "Instead of flat one-hot encoding:\n",
    "- 🏗️ **Stack-level features:** Group technologies into meaningful categories (frontend, backend, data science).\n",
    "- 🔬 **Technology-level features:** Preserve granular signals for high-impact individual technologies.\n",
    "\n",
    "---\n",
    "\n",
    "**3️⃣ Salary-Proportional Weighting Strategy**\n",
    "- **Core Problem:**  \n",
    "  Not all technologies within a stack equally impact salary.\n",
    "- **Solution:**  \n",
    "  Weight features **proportionally to salary impact**:\n",
    "\n",
    "- **Rationale:**  \n",
    "Retains genuine salary signals from both high-paying outliers and common technologies.\n",
    "\n",
    "---\n",
    "\n",
    "### ⚙️ **Technical Decisions Made**\n",
    "\n",
    "- **Weighting Approach:**  \n",
    "Chose raw salary differences over RBF smoothing for now — to maintain interpretability.  \n",
    "➡️ Will revisit after performance tests.\n",
    "\n",
    "- **Experimental Plan:**  \n",
    "1. Analyze technology → salary relationships  \n",
    "2. Implement proportional weighting  \n",
    "3. Benchmark against simple stack groups  \n",
    "4. Measure correlation & regression metrics  \n",
    "5. Then build a robust transformer for the production pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "### 📚 **Learning Links to Chapter 2 Concepts**\n",
    "\n",
    "- 🛠️ **Feature Engineering Pipelines:**  \n",
    "Following Aurélien’s Ch.2 by separating **experimental exploration from production steps**.\n",
    "\n",
    "- 🎭 **Handling Categorical Variables:**  \n",
    "Moving beyond basic one-hots to **domain-driven encodings** that capture business realities.\n",
    "\n",
    "- 🚀 **Taming the Curse of Dimensionality:**  \n",
    "Recognizing how high-cardinality categoricals inflate feature space and strategically compressing it.\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 **Next Steps**\n",
    "1. Implement salary analysis per technology  \n",
    "2. Build proportional weighting system  \n",
    "3. Create experimental features & test correlations  \n",
    "4. Compare against baseline stack grouping  \n",
    "5. Document insights before pipeline production.\n",
    "\n",
    "---\n",
    "\n",
    "### 🌟 **Key Takeaway**\n",
    "> 🧠 The best feature engineering blends **domain expertise** (understanding real tech clusters)  \n",
    "> with **statistical rigor** (weighting by salary impact).  \n",
    "> This is where **human judgment becomes irreplaceable** in an ML pipeline.\n",
    "\n",
    "---\n",
    "\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834f5dc0",
   "metadata": {},
   "source": [
    "#### __EDA__\n",
    "\n",
    "### 📌 **Insight**\n",
    "After exploratory scatter plots of `YearsCode` vs `ConvertedCompYearly`, we observed extreme variance and no clear linear relationship.  \n",
    "This confirmed that raw years of experience does **not translate directly into salary** due to multiple hidden confounders (role, location, negotiation, industry).\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 **Decision**\n",
    "- **1. Log-transform salary**  \n",
    "  To stabilize variance and interpret coefficients in percentage changes, we applied:\n",
    "  \n",
    "  LogSalary = log1p(ConvertedCompYearly)\n",
    "\n",
    "This reduces the impact of extreme salary outliers and makes relationships more linear.\n",
    "\n",
    "- **2. Bucketize years of experience**  \n",
    "Recognizing the diminishing returns of experience, we plan to group `YearsCode` into meaningful categories (e.g., 0-2 yrs, 3-5 yrs, etc).  \n",
    "This approach captures non-linear experience effects and prevents outlier distortion.\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 **Next step**\n",
    "- Define logical buckets for `YearsCode` and `YearsCodePro` based on both:\n",
    "- **Domain intuition** (typical junior, mid, senior ranges), and\n",
    "- **Actual data distributions** (observed quantiles).\n",
    "- Explore pivot plots of average `LogSalary` vs experience buckets to confirm expected patterns.\n",
    "- Encode these buckets as categorical features in our modeling pipeline.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55bcc89",
   "metadata": {},
   "source": [
    "#### __HEADING_HERE__\n",
    "\n",
    "- __Decision:__\n",
    "- ___Why?___\n",
    "- __Challenges:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ca1ca7",
   "metadata": {},
   "source": [
    "#### __HEADING_HERE__\n",
    "\n",
    "- __Decision:__\n",
    "- ___Why?___\n",
    "- __Challenges:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad0391a",
   "metadata": {},
   "source": [
    "#### __HEADING_HERE__\n",
    "\n",
    "- __Decision:__\n",
    "- ___Why?___\n",
    "- __Challenges:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dd7369",
   "metadata": {},
   "source": [
    "#### __HEADING_HERE__\n",
    "\n",
    "- __Decision:__\n",
    "- ___Why?___\n",
    "- __Challenges:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350f911d",
   "metadata": {},
   "source": [
    "#### __HEADING_HERE__\n",
    "\n",
    "- __Decision:__\n",
    "- ___Why?___\n",
    "- __Challenges:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf601bd",
   "metadata": {},
   "source": [
    "#### __HEADING_HERE__\n",
    "\n",
    "- __Decision:__\n",
    "- ___Why?___\n",
    "- __Challenges:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c0c5e",
   "metadata": {},
   "source": [
    "#### __HEADING_HERE__\n",
    "\n",
    "- __Decision:__\n",
    "- ___Why?___\n",
    "- __Challenges:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebdd473",
   "metadata": {},
   "source": [
    "#### __HEADING_HERE__\n",
    "\n",
    "- __Decision:__\n",
    "- ___Why?___\n",
    "- __Challenges:__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70489d9d",
   "metadata": {},
   "source": [
    "#### __HEADING_HERE__\n",
    "\n",
    "- __Decision:__\n",
    "- ___Why?___\n",
    "- __Challenges:__"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
