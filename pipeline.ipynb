{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd4ea7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AdvancedFeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, salaries, y=None):\n",
    "        self.feature_names_in = salaries.columns.tolist()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, salaries):\n",
    "        salaries = salaries.copy()\n",
    "        \n",
    "        # Convert to numeric (your existing code)\n",
    "        salaries['YearsCode'] = pd.to_numeric(salaries['YearsCode'], errors='coerce').fillna(0)\n",
    "        salaries['YearsCodePro_B'] = pd.to_numeric(salaries['YearsCodePro_B'], errors='coerce').fillna(0)\n",
    "        \n",
    "        # Your feature engineering logic here\n",
    "        skill_columns = [col for col in salaries.columns if col.endswith('_Bucket')]\n",
    "        \n",
    "        salaries['skill_diversity'] = X[skill_columns].apply(\n",
    "            lambda row: len([val for val in row if val not in ['None', 'Other', 'Not Specified']]), axis=1\n",
    "        ).fillna(0)\n",
    "        \n",
    "        salaries['experience_consistency'] = salaries['YearsCodePro_B'] / (salaries['YearsCode'] + 1)\n",
    "        salaries['experience_consistency'] = salaries['experience_consistency'].clip(0, 1).fillna(0)\n",
    "        \n",
    "        seniority_keywords = ['Senior', 'Lead', 'Staff', 'Principal', 'Manager', 'Director']\n",
    "        salaries['is_senior_role'] = salaries['DevType_Bucket'].str.contains('|'.join(seniority_keywords), case=False, na=False)\n",
    "        \n",
    "        salaries['professional_experience_factor'] = (\n",
    "            salaries['YearsCodePro_B'] * 0.7 + \n",
    "            salaries['experience_consistency'] * 0.2 + \n",
    "            salaries['is_senior_role'].astype(int) * 0.1\n",
    "        )\n",
    "        \n",
    "        salaries['experience_skill_ratio'] = salaries['skill_diversity'] / (salaries['YearsCodePro_B'] + 1)\n",
    "        \n",
    "        salaries['senior_experience_match'] = (\n",
    "            salaries['is_senior_role'] & (salaries['YearsCodePro_B'] >= 5)\n",
    "        ).astype(int)\n",
    "        \n",
    "        return salaries\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        if input_features is None: \n",
    "            input_features = getattr(self, 'feature_names_in', [])\n",
    "\n",
    "        if hasattr(input_features, 'tolist'):\n",
    "            input_features = input_features.tolist()\n",
    "\n",
    "        engineered_features = [\n",
    "            'skill_diversity', 'experience_consistency', 'is_senior_role',\n",
    "            'professional_experience_factor', 'experience_skill_ratio', 'senior_experience_match'\n",
    "        ]\n",
    "\n",
    "        return input_features + engineered_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856a3f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrgSizeBinner(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, salaries, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, salaries):\n",
    "        salaries = salaries.copy()\n",
    "        \n",
    "        orgsize_bins = {\n",
    "            'large_enterprise': ['10,000 or more employees'],\n",
    "            'enterprise': ['5,000 to 9,999 employees'], \n",
    "            'mid_company': ['1,000 to 4,999 employees'],\n",
    "            'small_company': ['500 to 999 employees', '100 to 499 employees'],\n",
    "            'startup': ['20 to 99 employees', '2 to 19 employees'],\n",
    "            'freelancer': ['Just me - I am a freelancer, sole proprietor, etc.'],\n",
    "            'other': ['I don\\'t know', 'Not specified']\n",
    "        }\n",
    "        \n",
    "        salaries['OrgSize_Binned'] = 'other'  # default\n",
    "        for bin_name, categories in orgsize_bins.items():\n",
    "            salaries.loc[salaries['OrgSize'].isin(categories), 'OrgSize_Binned'] = bin_name\n",
    "            \n",
    "        return salaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a968ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED PIPELINE with CustomTransformer for Feature Engineering. \n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "ordinal_cols = ['EdLevel_Bucket']\n",
    "\n",
    "onehot_cols = ['Employment_Category_Bucket']\n",
    "\n",
    "target_cols = ['DevType_Bucket', 'PlatformHaveWorkedWith_Bucket', 'WebframeHaveWorkedWith_Bucket', 'LanguageHaveWorkedWith_Bucket', 'ToolsTechHaveWorkedWith_Bucket', 'YearsCodePro_B']\n",
    "\n",
    "numerical_cols = ['Age_Encoded']\n",
    "\n",
    "edlevel_order = ['Masters', 'Bachelors', 'No_Degree', 'Associates']\n",
    "\n",
    "all_ordinal_orders = [edlevel_order]\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('ordinal', OrdinalEncoder(categories=all_ordinal_orders), ordinal_cols),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=True), onehot_cols),\n",
    "        ('target', CustomTargetEncoder(), target_cols),\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "new_pipeline = Pipeline(steps=[\n",
    "    ('orgsize_binning', OrgSizeBinner()),\n",
    "    ('feature_engineering', AdvancedFeatureEngineer()),\n",
    "    ('preprocessor', preprocessor)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050dbba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_professional_tech_multiple(tech_string):\n",
    "    \"\"\"\n",
    "    Applies hierarchical keyword-based bucketing to a semi-colon separated string of technologies.\n",
    "    It iterates through each technology and assigns the first bucket that matches.\n",
    "    \"\"\"\n",
    "    if pd.isna(tech_string):\n",
    "        return 'None'\n",
    "    \n",
    "    lower_tech_string = str(tech_string).lower()\n",
    "\n",
    "    if 'none of these' in lower_tech_string:\n",
    "        return 'None'\n",
    "\n",
    "    buckets = {\n",
    "\n",
    "        'AI/ML': ['ai', 'machine learning', 'ml', 'deep learning', 'neural network', 'nlp', 'natural language', 'computer vision', 'tensorflow', 'pytorch', 'keras', 'scikit-learn', 'openai'],\n",
    "        'Data Science & Analytics': ['data science', 'data analysis', 'analytics', 'big data', 'hadoop', 'spark', 'pandas', 'numpy', 'tableau', 'power bi', 'databricks', 'snowflake'],\n",
    "        \n",
    "\n",
    "        'DevOps & Cloud': ['devops', 'ci/cd', 'continuous integration', 'continuous delivery', 'docker', 'kubernetes', 'terraform', 'ansible', 'jenkins', 'aws', 'azure', 'gcp', 'cloud', 'observability'],\n",
    "        \n",
    "\n",
    "        'Web Development': ['web', 'frontend', 'backend', 'full-stack', 'javascript', 'react', 'angular', 'vue', 'node.js', 'django', 'flask', 'ruby on rails', 'php', 'asp.net'],\n",
    "        'Mobile Development': ['mobile', 'ios', 'android', 'swift', 'kotlin', 'react native', 'flutter', 'xamarin'],\n",
    "        'Databases': ['database', 'sql', 'nosql', 'postgresql', 'mysql', 'sql server', 'mongodb', 'redis', 'cassandra', 'firebase'],\n",
    "        'Testing & QA': ['testing', 'qa', 'quality assurance', 'selenium', 'jest', 'pytest', 'cypress', 'junit'],\n",
    "        'Security': ['security', 'cybersecurity', 'infosec', 'penetration testing', 'pen testing'],\n",
    "        'Developer Tools': ['git', 'github', 'gitlab', 'jira', 'visual studio code', 'ide'],\n",
    "        \n",
    "\n",
    "        'Architecture & Practices': ['microservices', 'developer portal', 'innersource']\n",
    "    }\n",
    "\n",
    "    listed_techs = [tech.strip().lower() for tech in str(tech_string).split(';')]\n",
    "\n",
    "    for tech in listed_techs:\n",
    "        for bucket, keywords in buckets.items():\n",
    "            if any(keyword in tech for keyword in keywords):\n",
    "                return bucket\n",
    "\n",
    "    return 'Other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63b914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "\n",
    "top_10_countries = features['Country'].value_counts().nlargest(10).index\n",
    "\n",
    "# .where() keeps the value if the condition is true, otherwise replaces it with 'Other'\n",
    "features['Country_Grouped'] = features['Country'].where(features['Country'].isin(top_10_countries), 'Other')\n",
    "\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "features['Country_Grouped'] = imputer.fit_transform(features[['Country_Grouped']]).ravel()\n",
    "\n",
    "\n",
    "print(features['Country_Grouped'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ad8636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Transformer for highly sensitive traget encoding \n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class CustomTargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if y is None:\n",
    "            raise ValueError(\"Target encoder requires y during fit\")\n",
    "\n",
    "        if not isinstance(y, pd.Series):\n",
    "            y = pd.Series(y, name=\"target\")\n",
    "        else:   \n",
    "            y = y.copy()\n",
    "\n",
    "        self.global_mean_ = y.mean()\n",
    "        \n",
    "        self.encodings_ = {}\n",
    "        \n",
    "        for col in X.columns:\n",
    "            salary = pd.concat([X[[col]], y], axis=1)\n",
    "            self.encodings_[col] = salary.groupby(col)[y.name].mean()\n",
    "            \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \n",
    "        X_new = X.copy()\n",
    "        for col in X.columns:\n",
    "            X_new[col] = X_new[col].map(self.encodings_[col]).fillna(self.global_mean_)\n",
    "        return X_new\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "\n",
    "        if input_features is None:\n",
    "            return self.feature_names_in_\n",
    "        return input_features\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stck",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
